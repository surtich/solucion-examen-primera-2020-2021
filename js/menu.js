const menu = 
["Introduction",
 "Preliminaries",
    ["Data Manipulation",
     "Data Preprocessing",
     "Linear Algebra",
     "Calculus",
     "Automatic Differentiation",
     "Probability",
     "Documentation"],
 "Linear Neural Networks",
    ["Linear Regression",
     "Linear Regression Implementation from Scratch",
     "Concise Implementation of Linear Regression",
     "Softmax Regression",
     "The Image Classification Dataset",
     "Implementation of Softmax Regression from Scratch",
     "Concise Implementation of Softmax Regression"],
 "Multilayer Perceptrons",
    ["Multilayer Perceptrons",
     "Implementation of Multilayer Perceptrons from Scratch",
     "Concise Implementation of Multilayer Perceptrons",
     "Model Selection, Underfitting, and Overfitting",
     "Weight Decay",
     "Dropout",
     "Forward Propagation, Backward Propagation, and Computational Graphs",
     "Numerical Stability and Initialization",
     "Environment and Distribution Shift",
     "Predicting House Prices on Kaggle"],
 "Deep Learning Computation",
    ["Layers and Blocks",
     "Parameter Management",
     "Deferred Initialization",
     "Custom Layers",
     "File I/O",
     "GPUs"],
 "Convolutional Neural Networks",
    ["From Fully-Connected Layers to Convolutions",
     "Convolutions for Images",
     "Padding and Stride",
     "Multiple Input and Multiple Output Channels",
     "Pooling",
     "Convolutional Neural Networks (LeNet)"],
 "Modern Convolutional Neural Networks",
    ["Deep Convolutional Neural Networks (AlexNet)",
     "Networks Using Blocks (VGG)",
     "Network in Network (NiN)",
     "Networks with Parallel Concatenations (GoogLeNet)",
     "Batch Normalization",
     "Residual Networks (ResNet)",
     "Densely Connected Networks (DenseNet)"],
 "Recurrent Neural Networks",
    ["Sequence Models",
     "Text Preprocessing",
     "Language Models and the Dataset",
     "Recurrent Neural Networks",
     "Implementation of Recurrent Neural Networks from Scratch",
     "Concise Implementation of Recurrent Neural Networks",
     "Backpropagation Through Time"],
 "Modern Recurrent Neural Networks",
    ["Gated Recurrent Units (GRU)",
     "Long Short-Term Memory (LSTM)",
     "Deep Recurrent Neural Networks",
     "Bidirectional Recurrent Neural Networks",
     "Machine Translation and the Dataset",
     "Encoder-Decoder Architecture",
     "Sequence to Sequence Learning",
     "Beam Search"],
 "Attention Mechanisms",
    ["Attention Mechanisms",
     "Sequence to Sequence with Attention Mechanisms",
     "Transformer"],
 "Optimization Algorithms",
    ["Optimization and Deep Learning",
     "Convexity",
     "Gradient Descent",
     "Stochastic Gradient Descent",
     "Minibatch Stochastic Gradient Descent",
     "Momentum",
     "Adagrad",
     "RMSProp",
     "Adadelta",
     "Adam",
     "Learning Rate Scheduling"],
 "Computational Performance",
    ["Compilers and Interpreters",
     "Asynchronous Computation",
     "Automatic Parallelism",
     "Hardware",
     "Training on Multiple GPUs",
     "Concise Implementation for Multiple GPUs",
     "Parameter Servers"],
 "Computer Vision",
    ["Image Augmentation",
     "Fine-Tuning",
     "Object Detection and Bounding Boxes",
     "Anchor Boxes",
     "Multiscale Object Detection",
     "The Object Detection Dataset",
     "Single Shot Multibox Detection (SSD)",
     "Region-based CNNs (R-CNNs)",
     "Semantic Segmentation and the Dataset",
     "Transposed Convolution",
     "Fully Convolutional Networks (FCN)",
     "Neural Style Transfer",
     "Image Classification (CIFAR-10) on Kaggle",
     "Dog Breed Identification (ImageNet Dogs) on Kaggle"],
 "Natural Language Processing: Pretraining",
    ["Word Embedding (word2vec)",
     "Approximate Training",
     "The Dataset for Pretraining Word Embedding",
     "Pretraining word2vec",
     "Word Embedding with Global Vectors (GloVe)",
     "Subword Embedding",
     "Finding Synonyms and Analogies",
     "Bidirectional Encoder Representations from Transformers (BERT)",
     "The Dataset for Pretraining BERT",
     "Pretraining BERT"],
 "Natural Language Processing: Applications",
    ["Sentiment Analysis and the Dataset",
     "Sentiment Analysis: Using Recurrent Neural Networks",
     "Sentiment Analysis: Using Convolutional Neural Networks",
     "Natural Language Inference and the Dataset",
     "Natural Language Inference: Using Attention",
     "Fine-Tuning BERT for Sequence-Level and Token-Level Applications",
     "Natural Language Inference: Fine-Tuning BERT"],
 "Recommender Systems",
    ["Overview of Recommender Systems",
     "The MovieLens Dataset",
     "Matrix Factorization",
     "AutoRec: Rating Prediction with Autoencoders",
     "Personalized Ranking for Recommender Systems",
     "Neural Collaborative Filtering for Personalized Ranking",
     "Sequence-Aware Recommender Systems",
     "Feature-Rich Recommender Systems",
     "Factorization Machines",
     "Deep Factorization Machines"],
 "Generative Adversarial Networks",
    ["Generative Adversarial Networks",
     "Deep Convolutional Generative Adversarial Networks"],
 "Appendix: Mathematics for Deep Learning",
    ["Geometry and Linear Algebraic Operations",
     "Eigendecompositions",
     "Single Variable Calculus",
     "Multivariable Calculus",
     "Integral Calculus",
     "Random Variables",
     "Maximum Likelihood",
     "Distributions",
     "Naive Bayes",
     "Statistics",
     "Information Theory"],
 "Appendix: Tools for Deep Learning",
    ["Using Jupyter",
     "Using Amazon SageMaker",
     "Using AWS EC2 Instances",
     "Using Google Colab",
     "Selecting Servers and GPUs",
     "Contributing to This Book",
     "d2l API Document"],
]
